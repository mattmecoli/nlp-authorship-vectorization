{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Authorship Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Source: http://www.gutenberg.org/\n",
    "\n",
    "14 American and British authors (7 male, 7 female), 2 books each, from 7 different literary periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/anaconda3/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning:\n",
      "\n",
      "compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "import os\n",
    "import re\n",
    "from gensim.models.doc2vec import *\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import colorlover as cl\n",
    "from IPython.display import HTML\n",
    "from keras import regularizers\n",
    "from keras.layers import Dropout\n",
    "from keras import optimizers\n",
    "import ipywidgets as widgets\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "*The raw code for this Jupyter notebook is by default hidden for easier reading.\n",
    "To toggle on/off the raw code, click <a href=\"javascript:code_toggle()\">here</a>.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "books_df = pd.read_csv('AuthorsCSVPresentationVersion.csv')\n",
    "books_df = books_df.loc[:,:'Period']\n",
    "books_df = books_df.dropna()\n",
    "books_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['FScottFitzgerald', 'JackLondon', 'KateChopin', 'MaryWollstonecraft', 'CharlesDickens', 'NathanielHawthorne', 'JaneAustin', 'EdithWharton', 'MargaretFuller', 'VirginiaWoolf', 'HenryDavidThoreau', 'MarkTwain', 'MaryShelley', 'JohnLocke'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleaning and Tokenizing Words for train texts\n",
    "\n",
    "train_folder = Path.cwd().joinpath(\"rawtextfiles\")\n",
    "\n",
    "clean_books = {}\n",
    "\n",
    "for filename in train_folder.iterdir():\n",
    "    with open(str(filename), encoding='utf-8', errors='ignore') as fhand:\n",
    "        text = fhand.readlines()\n",
    "        clean_text = []\n",
    "        for line in text:\n",
    "            clean_line = re.sub('[^A-Za-z0-9 ]+', '', line)\n",
    "            words = clean_line.split(\" \")\n",
    "            for word in words[:]:\n",
    "                if len(word) != 0:\n",
    "                    clean_text.append(word)\n",
    "        if len(clean_text) > 100 :\n",
    "            file_name = str(filename).split('-')[1]\n",
    "            clean_books[file_name] = clean_books.get(file_name, []) + clean_text[350:]\n",
    "        #         clean_books[file_name] = clean_text[350:]\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "for k, v in clean_books.items():\n",
    "    if len(v) < 1:\n",
    "        del clean_books[k]     \n",
    "\n",
    "clean_books.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import StanfordNERTagger #this is a built in nltk wrapper for StanfordNER which is written in java\n",
    "\n",
    "classifier_doc_path = Path.cwd().joinpath(\"stanford_ner/classifiers/english.muc.7class.distsim.crf.ser.gz\")\n",
    "classifier_dir_path = Path.cwd().joinpath(\"stanford_ner/stanford_ner.jar\")\n",
    "\n",
    "st = StanfordNERTagger(str(classifier_doc_path), str(classifier_dir_path), encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "word_loss_NER_stan = {}\n",
    "\n",
    "for author in clean_books.keys():\n",
    "    tagged_corpus = st.tag(clean_books[author])\n",
    "    NER_corpus =[word.lower() for word, tag in tagged_corpus if tag == 'O']\n",
    "    clean_books[author] = NER_corpus\n",
    "    word_loss_NER_stan[author] = [len(tagged_corpus) - len(NER_corpus)]\n",
    "    removed_words = []\n",
    "    while len(removed_words) < 10:\n",
    "            removed_words = [(word, tag) for word, tag in tagged_corpus if tag != 'O']\n",
    "    word_loss_NER_stan[author].append(removed_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3040,\n",
       " [('Bors', 'PERSON'),\n",
       "  ('de', 'PERSON'),\n",
       "  ('Ganis', 'PERSON'),\n",
       "  ('Sir', 'PERSON'),\n",
       "  ('Launcelot', 'PERSON'),\n",
       "  ('Lake', 'LOCATION'),\n",
       "  ('Sir', 'LOCATION'),\n",
       "  ('Galahad', 'LOCATION'),\n",
       "  ('Arthur', 'PERSON'),\n",
       "  ('Round', 'ORGANIZATION')]]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_loss_NER_stan['MarkTwain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CharlesDickens': '2.579%',\n",
       " 'EdithWharton': '3.844%',\n",
       " 'FScottFitzgerald': '3.493%',\n",
       " 'HenryDavidThoreau': '2.162%',\n",
       " 'JackLondon': '2.417%',\n",
       " 'JaneAustin': '3.548%',\n",
       " 'JohnLocke': '0.234%',\n",
       " 'KateChopin': '3.171%',\n",
       " 'MargaretFuller': '1.402%',\n",
       " 'MarkTwain': '1.627%',\n",
       " 'MaryShelley': '1.355%',\n",
       " 'MaryWollstonecraft': '0.538%',\n",
       " 'NathanielHawthorne': '1.965%',\n",
       " 'VirginiaWoolf': '3.345%'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_loss_NER_percents_stan = {}\n",
    "\n",
    "for author in word_loss_NER_stan.keys():\n",
    "    word_loss_NER_percents_stan[author] = \"{:.3%}\".format((word_loss_NER_stan[author][0] / (word_loss_NER_stan[author][0]+len(clean_books[author]))))\n",
    "\n",
    "word_loss_NER_percents_stan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.getcwd() + '/' + '250Paragraphs_150Words.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>sex</th>\n",
       "      <th>period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fell together as modest people will in the tai...</td>\n",
       "      <td>MarkTwain</td>\n",
       "      <td>male</td>\n",
       "      <td>realism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>that he ran away as he were wood demented for ...</td>\n",
       "      <td>MarkTwain</td>\n",
       "      <td>male</td>\n",
       "      <td>realism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>had ye not been therefore to yield us unto him...</td>\n",
       "      <td>MarkTwain</td>\n",
       "      <td>male</td>\n",
       "      <td>realism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the advantage so i judged it best to humor him...</td>\n",
       "      <td>MarkTwain</td>\n",
       "      <td>male</td>\n",
       "      <td>realism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>girls were always naked but nobody seemed to k...</td>\n",
       "      <td>MarkTwain</td>\n",
       "      <td>male</td>\n",
       "      <td>realism</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     author   sex   period\n",
       "0  fell together as modest people will in the tai...  MarkTwain  male  realism\n",
       "1  that he ran away as he were wood demented for ...  MarkTwain  male  realism\n",
       "2  had ye not been therefore to yield us unto him...  MarkTwain  male  realism\n",
       "3  the advantage so i judged it best to humor him...  MarkTwain  male  realism\n",
       "4  girls were always naked but nobody seemed to k...  MarkTwain  male  realism"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = list(set((df['author'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split \n",
    "def split_by_authors():\n",
    "    df_split ={}\n",
    "    for author in authors:\n",
    "        df_ = df[df['author'] == author]\n",
    "        df_split[author] = df_\n",
    "    return df_split\n",
    "\n",
    "df_by_authors = split_by_authors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_df = pd.DataFrame(columns=list(df.columns))\n",
    "test_set_df = pd.DataFrame(columns=list(df.columns))\n",
    "validation_set_df = pd.DataFrame(columns=list(df.columns))\n",
    "for author in authors:\n",
    "    train_set = df_by_authors[author].sample(int((len(df_by_authors[author]))*0.7))\n",
    "    test_val_set = df_by_authors[author].drop(train_set.index)\n",
    "    validation_set = test_val_set.sample(int((len(df_by_authors[author]))*0.1))\n",
    "    test_set = test_val_set.drop(validation_set.index)\n",
    "    train_set_df = pd.concat([train_set_df,train_set])\n",
    "    test_set_df = pd.concat([test_set_df,test_set])\n",
    "    validation_set_df = pd.concat([validation_set_df,validation_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resetting the index\n",
    "train_set_df = train_set_df.reset_index()\n",
    "test_set_df = test_set_df.reset_index()\n",
    "validation_set_df = validation_set_df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['that', 'there', 'must', 'be', 'an', 'eternal', 'being', 'and', 'that', 'being', 'must', 'also', 'be', 'knowing', 'yet', 'it', 'does', 'not', 'follow', 'but', 'that', 'thinking', 'being', 'may', 'also', 'be', 'material', 'let', 'it', 'be', 'so', 'it', 'equally', 'still', 'follows', 'that', 'there', 'is', 'a', 'god', 'for', 'there', 'be', 'an', 'eternal', 'omniscient', 'omnipotent', 'being', 'it', 'is', 'certain', 'that', 'there', 'is', 'a', 'god', 'whether', 'you', 'imagine', 'that', 'being', 'to', 'be', 'material', 'or', 'no', 'but', 'herein', 'i', 'suppose', 'lies', 'the', 'danger', 'and', 'deceit', 'of', 'that', 'suppositionthere', 'being', 'no', 'way', 'to', 'avoid', 'the', 'demonstration', 'that', 'there', 'is', 'an', 'eternal', 'knowing', 'being', 'men', 'devoted', 'to', 'matter', 'would', 'willingly', 'have', 'it', 'granted', 'that', 'that', 'knowing', 'being', 'is', 'material', 'and', 'then', 'letting', 'slide', 'out', 'of', 'their', 'minds', 'or', 'the', 'discourse', 'the', 'demonstration', 'whereby', 'an', 'eternal', 'knowing', 'being', 'was', 'proved', 'necessarily', 'to', 'exist', 'would', 'argue', 'all', 'to', 'be', 'matter', 'and', 'so', 'deny', 'a', 'god', 'that', 'is', 'an', 'eternal', 'cogitative', 'being', 'whereby', 'they', 'are', 'so'], tags=['JohnLocke', 'enlightenment', 'male'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create TaggedDocument objects for train_corpus\n",
    "train_corpus = []\n",
    "for i in range(0, len(train_set_df)):\n",
    "    doc = TaggedDocument(train_set_df['text'][i].split(), [train_set_df['author'][i], \n",
    "                                                            train_set_df['period'][i], \n",
    "                                                            train_set_df['sex'][i]])   \n",
    "    train_corpus.append(doc)\n",
    "train_corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create corpus objects for test_corpus\n",
    "test_corpus = []\n",
    "for i in range(0, len(test_set_df)):\n",
    "    doc = test_set_df['text'][i].split()\n",
    "    test_corpus.append(doc)\n",
    "    \n",
    "# Create corpus objects for val_corpus\n",
    "val_corpus = []\n",
    "for i in range(0, len(validation_set_df)):\n",
    "    doc = validation_set_df['text'][i].split()\n",
    "    val_corpus.append(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vec_size = 20\n",
      "min_count = 2\n",
      "epochs = 20\n",
      "alpha = 0.025\n"
     ]
    }
   ],
   "source": [
    "# Declare hyperparamters \n",
    "vec_size = 20\n",
    "min_count = 2\n",
    "epochs = 20\n",
    "alpha = 0.025\n",
    "min_alpha = 0.025\n",
    "\n",
    "print('vec_size = 20')\n",
    "print('min_count = 2')\n",
    "print('epochs = 20')\n",
    "print('alpha = 0.025')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doc2Vec - initializing the model\n",
    "# %%time \n",
    "\n",
    "model = Doc2Vec(vector_size=vec_size,\n",
    "                min_count=min_count,\n",
    "                epochs=epochs,\n",
    "                alpha = alpha,\n",
    "                min_alpha = min_alpha)\n",
    "\n",
    "model.build_vocab(train_corpus)\n",
    "\n",
    "model.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.docvecs)\n",
    "# should be 23\n",
    "# two for gender, seven for periods, and fourteen for authors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### < Cosine Similarity between documents and labels >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author        JohnLocke\n",
       "sex                male\n",
       "period    enlightenment\n",
       "Name: 23, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 most similar vectors to the sample corpus by Virginia Woolf:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('male', 0.6455762982368469),\n",
       " ('JohnLocke', 0.6128061413764954),\n",
       " ('enlightenment', 0.606026291847229),\n",
       " ('VirginiaWoolf', 0.3474712073802948),\n",
       " ('female', 0.3442780673503876),\n",
       " ('JaneAustin', 0.12966743111610413),\n",
       " ('victorian', 0.12321652472019196),\n",
       " ('realism', 0.1180659681558609),\n",
       " ('EdithWharton', 0.10082387924194336),\n",
       " ('MarkTwain', 0.09579001367092133)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inferred_vector = model.infer_vector(test_corpus[23])\n",
    "sims = model.docvecs.most_similar([inferred_vector])\n",
    "# print(inferred_vector)\n",
    "display(test_set_df.loc[23][['author', 'sex', 'period']])\n",
    "print('Top 10 most similar vectors to the sample corpus by Virginia Woolf:')\n",
    "sims #23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derive_score_train(df, corpus):\n",
    "    score_list = {}\n",
    "    for i in range(0, len(test_set_df)):\n",
    "        cos_sims = []\n",
    "        inferred_vector = model.infer_vector(corpus[i].words)\n",
    "        sims = dict(model.docvecs.most_similar([inferred_vector]))\n",
    "        if test_set_df.iloc[i]['author'] in list(sims.keys()):\n",
    "            cos_sims.append(sims[test_set_df.iloc[i]['author']])\n",
    "        if test_set_df.iloc[i]['sex'] in list(sims.keys()):\n",
    "            cos_sims.append(sims[test_set_df.iloc[i]['sex']])\n",
    "        if test_set_df.iloc[i]['period'] in list(sims.keys()):\n",
    "            cos_sims.append(sims[test_set_df.iloc[i]['period']])\n",
    "        total_score = sum(cos_sims)\n",
    "        score_list[test_set_df.iloc[i]['index']] = total_score/3\n",
    "    return score_list\n",
    "\n",
    "def derive_score_test(df, corpus):\n",
    "    score_list = {}\n",
    "    for i in range(0, len(test_set_df)):\n",
    "        cos_sims = []\n",
    "        inferred_vector = model.infer_vector(corpus[i])\n",
    "        sims = dict(model.docvecs.most_similar([inferred_vector]))\n",
    "        if test_set_df.iloc[i]['author'] in list(sims.keys()):\n",
    "            cos_sims.append(sims[test_set_df.iloc[i]['author']])\n",
    "        if test_set_df.iloc[i]['sex'] in list(sims.keys()):\n",
    "            cos_sims.append(sims[test_set_df.iloc[i]['sex']])\n",
    "        if test_set_df.iloc[i]['period'] in list(sims.keys()):\n",
    "            cos_sims.append(sims[test_set_df.iloc[i]['period']])\n",
    "        total_score = sum(cos_sims)\n",
    "        score_list[test_set_df.iloc[i]['index']] = total_score/3\n",
    "    return score_list\n",
    "\n",
    "score_list_train = derive_score_train(train_set_df, train_corpus)\n",
    "score_list_test = derive_score_test(test_set_df, test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# score_avg_train = sum(score_list_train.values()) / len(score_list_train)\n",
    "# print('accuracy score for train set is ' + str(round(score_avg_train*100, 2)) + '%')\n",
    "\n",
    "# score_avg_test = sum(score_list_test.values()) / len(score_list_test)\n",
    "# print('accuracy score for test set is ' + str(round(score_avg_test*100, 2)) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcurate the weighted score\n",
    "\n",
    "weighted_score_list_test = {}  # for test set\n",
    "for i in range(0, len(test_set_df)):\n",
    "    cos_sims = []\n",
    "    inferred_vector = model.infer_vector(test_corpus[i])\n",
    "    sims = dict(model.docvecs.most_similar([inferred_vector]))\n",
    "    if test_set_df.iloc[i]['author'] in list(sims.keys()):\n",
    "        cos_sims.append(sims[test_set_df.iloc[i]['author']]*(23-(list(sims.keys()).index(test_set_df.iloc[i]['author']))))\n",
    "    if test_set_df.iloc[i]['sex'] in list(sims.keys()):\n",
    "        cos_sims.append(sims[test_set_df.iloc[i]['sex']]*(23-(list(sims.keys()).index(test_set_df.iloc[i]['sex']))))\n",
    "    if test_set_df.iloc[i]['period'] in list(sims.keys()):\n",
    "        cos_sims.append(sims[test_set_df.iloc[i]['period']]*(23-(list(sims.keys()).index(test_set_df.iloc[i]['period']))))\n",
    "    total_score = sum(cos_sims)\n",
    "    weighted_score_list_test[test_set_df.iloc[i]['index']] = total_score/(23+22+21)\n",
    "\n",
    "weighted_score_list_train = {}  # for training set\n",
    "for i in range(0, len(train_set_df)):\n",
    "    cos_sims = []\n",
    "    inferred_vector = model.infer_vector(train_corpus[i].words)\n",
    "    sims = dict(model.docvecs.most_similar([inferred_vector]))\n",
    "    if train_set_df.iloc[i]['author'] in list(sims.keys()):\n",
    "        cos_sims.append(sims[train_set_df.iloc[i]['author']]*(23-(list(sims.keys()).index(train_set_df.iloc[i]['author']))))\n",
    "    if train_set_df.iloc[i]['sex'] in list(sims.keys()):\n",
    "        cos_sims.append(sims[train_set_df.iloc[i]['sex']]*(23-(list(sims.keys()).index(train_set_df.iloc[i]['sex']))))\n",
    "    if train_set_df.iloc[i]['period'] in list(sims.keys()):\n",
    "        cos_sims.append(sims[train_set_df.iloc[i]['period']]*(23-(list(sims.keys()).index(train_set_df.iloc[i]['period']))))\n",
    "    total_score = sum(cos_sims)\n",
    "    weighted_score_list_train[train_set_df.iloc[i]['index']] = total_score/(23+22+21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculated accuracy score for train set is 41.32%\n",
      "calculated accuracy score for test set is 34.43%\n"
     ]
    }
   ],
   "source": [
    "weighted_score_avg_train = sum(weighted_score_list_train.values()) / len(weighted_score_list_train)\n",
    "print('calculated accuracy score for train set is ' + str(round(weighted_score_avg_train*100, 2)) + '%')\n",
    "\n",
    "weighted_score_avg_test = sum(weighted_score_list_test.values()) / len(weighted_score_list_test)\n",
    "print('calculated accuracy score for test set is ' + str(round(weighted_score_avg_test*100, 2)) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector representation of all documents in list form (for training set)\n",
    "doc_vectors = [model.infer_vector(train_corpus[i].words) for i in range(0,len(train_corpus))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector representation of all documents in list form (for validation set)\n",
    "doc_vectors_val = [model.infer_vector(val_corpus[i]) for i in range(0,len(val_corpus))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector representation of all documents in list form (for test set)\n",
    "doc_vectors_test = [model.infer_vector(test_corpus[i]) for i in range(0,len(test_corpus))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Visualizations with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance ratio is 31.45%, 68.55% is lost by reducing the dimensionality\n"
     ]
    }
   ],
   "source": [
    "# reduce dimensionality to visualize the document vectors \n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 3)\n",
    "pca.fit(doc_vectors)\n",
    "doc_vectors_3d = pca.transform(doc_vectors) # transform the vectors to 3d space\n",
    "explained_variance_ratio = np.cumsum(pca.explained_variance_ratio_)[2]\n",
    "print('Explained variance ratio is {:.2f}%, {:.2f}% is lost by reducing the dimensionality'.format((explained_variance_ratio*100), (100-(explained_variance_ratio*100)))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create author, gender, period dictionaries for mapping \n",
    "num = list(range(0,len(authors)))\n",
    "author_num = dict(zip(authors, num))\n",
    "\n",
    "genders = list(set((df['sex'])))\n",
    "num_gen = list(range(0,len(genders)))\n",
    "sex_num = dict(zip(genders, num_gen))\n",
    "\n",
    "periods = list(set((df['period'])))\n",
    "num_period = list(range(0,len(periods)))\n",
    "period_num = dict(zip(periods, num_period))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframes for plotting\n",
    "doc_vectors_3d = pd.DataFrame(doc_vectors_3d)  \n",
    "\n",
    "# by author\n",
    "authors_df = pd.DataFrame([train_corpus[i].tags[0] for i in range(0, len(train_corpus))])\n",
    "doc_vectors_3d_with_author =pd.concat([doc_vectors_3d,authors_df], axis = 1)\n",
    "doc_vectors_3d_with_author.columns = ['x','y','z','author']\n",
    "doc_vectors_3d_with_author['author'] = doc_vectors_3d_with_author['author'].map(author_num)\n",
    "\n",
    "# by gender\n",
    "gender_df = pd.DataFrame([train_corpus[i].tags[2] for i in range(0, len(train_corpus))])\n",
    "doc_vectors_3d_with_gender =pd.concat([doc_vectors_3d,gender_df], axis = 1)\n",
    "doc_vectors_3d_with_gender.columns = ['x','y','z','sex']\n",
    "doc_vectors_3d_with_gender['sex'] = doc_vectors_3d_with_gender['sex'].map(sex_num)\n",
    "\n",
    "# by period\n",
    "period_df = pd.DataFrame([train_corpus[i].tags[1] for i in range(0, len(train_corpus))])\n",
    "doc_vectors_3d_with_period =pd.concat([doc_vectors_3d,period_df], axis = 1)\n",
    "doc_vectors_3d_with_period.columns = ['x','y','z','period']\n",
    "doc_vectors_3d_with_period['period'] = doc_vectors_3d_with_period['period'].map(period_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_map(category):\n",
    "    cmap = plt.cm.viridis\n",
    "    cmaplist = [cmap(i) for i in range(cmap.N)]\n",
    "    jump = 256//len(category)\n",
    "    cmaplist_ = [cmaplist[jump*i] for i in range(0,len(category))]\n",
    "    return cmaplist_\n",
    "\n",
    "cmap_author = color_map(authors)\n",
    "cmap_sex = color_map(genders)\n",
    "cmap_periods = color_map(periods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dab79e5aba1e4c9d8956ef5767140da5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Category:', options=('author', 'gender', 'time period'), value='au…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.update_plot(w)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.html.widgets import interact\n",
    "def update_plot(w):\n",
    "    if w == 'author':\n",
    "        traces_for_plot = []\n",
    "        for key, value in author_num.items():\n",
    "            df = doc_vectors_3d_with_author[doc_vectors_3d_with_author['author'] == value]\n",
    "            traces_for_plot.append(df)\n",
    "\n",
    "        traces_author = []\n",
    "        for trace in traces_for_plot:\n",
    "            trace1 = go.Scatter3d(\n",
    "            x = trace['x'],\n",
    "            y = trace['y'],\n",
    "            z = trace['z'],\n",
    "            mode='markers',\n",
    "            name = authors[trace['author'].values[0]],\n",
    "            marker=dict(\n",
    "                size=5,\n",
    "                color= 'rgba' + str(cmap_author[(trace['author'].values[0])]),\n",
    "            )\n",
    "            )\n",
    "            traces_author.append(trace1)\n",
    "\n",
    "        layout = go.Layout(showlegend=True)\n",
    "        # # Make a figure object\n",
    "        fig = go.Figure(data= traces_author, layout = layout)\n",
    "\n",
    "        # Send to Plotly and show in notebook\n",
    "        iplot(fig, filename='test1')\n",
    "    if w == 'gender':\n",
    "        traces_for_plot_sex = []\n",
    "        for key, value in sex_num.items():\n",
    "            df = doc_vectors_3d_with_gender[doc_vectors_3d_with_gender['sex'] == value]\n",
    "            traces_for_plot_sex.append(df)\n",
    "\n",
    "        traces_sex = []\n",
    "        for trace in traces_for_plot_sex:\n",
    "            trace1 = go.Scatter3d(\n",
    "            x = trace['x'],\n",
    "            y = trace['y'],\n",
    "            z = trace['z'],\n",
    "            mode='markers',\n",
    "            name = genders[trace['sex'].values[0]],\n",
    "            marker=dict(\n",
    "                size=5,\n",
    "                color= 'rgba' + str(cmap_sex[(trace['sex'].values[0])]),\n",
    "            )\n",
    "            )\n",
    "            traces_sex.append(trace1)\n",
    "\n",
    "        layout = go.Layout(showlegend=True)\n",
    "        # # Make a figure object\n",
    "        fig = go.Figure(data= traces_sex, layout = layout)\n",
    "\n",
    "        # Send to Plotly and show in notebook\n",
    "        iplot(fig, filename='test1')\n",
    "    if w == 'time period':\n",
    "        traces_for_plot_period = []\n",
    "        for key, value in period_num.items():\n",
    "            df = doc_vectors_3d_with_period[doc_vectors_3d_with_period['period'] == value]\n",
    "            traces_for_plot_period.append(df)\n",
    "\n",
    "        traces_period = []\n",
    "        for trace in traces_for_plot_period:\n",
    "            trace1 = go.Scatter3d(\n",
    "            x = trace['x'],\n",
    "            y = trace['y'],\n",
    "            z = trace['z'],\n",
    "            mode='markers',\n",
    "            name = periods[trace['period'].values[0]],\n",
    "            marker=dict(\n",
    "                size=5,\n",
    "                color= 'rgba' + str(cmap_periods[(trace['period'].values[0])]),\n",
    "            )\n",
    "            )\n",
    "            traces_period.append(trace1)\n",
    "\n",
    "        layout = go.Layout(showlegend=True)\n",
    "        # # Make a figure object\n",
    "        fig = go.Figure(data= traces_period, layout = layout)\n",
    "\n",
    "        # Send to Plotly and show in notebook\n",
    "        iplot(fig, filename='test1')\n",
    "\n",
    "w = widgets.Dropdown(\n",
    "    options= ['author','gender','time period'],\n",
    "    value='author',\n",
    "    description='Category:',\n",
    "    disabled=False)\n",
    "# w.observe(update_plot)\n",
    "interact(update_plot, w=w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Methods\n",
    "### Multilayer Perceptrons\n",
    "#### Gender Classification (binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe (gender) for CNN - train set \n",
    "doc_vec_df = pd.DataFrame(doc_vectors)\n",
    "gender_df.columns = ['sex']\n",
    "doc_vec_df_with_gender = pd.concat([doc_vec_df,gender_df], axis = 1)\n",
    "doc_vec_df_with_gender['sex'] = doc_vec_df_with_gender['sex'].map(sex_num)\n",
    "X_train = doc_vec_df_with_gender.drop(['sex'], axis = 1)\n",
    "y_train = doc_vec_df_with_gender.sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe (gender) for CNN - validation set\n",
    "doc_vec_df_val_set = pd.DataFrame(doc_vectors_val)\n",
    "gender_df_val_set = pd.DataFrame(validation_set_df['sex'])\n",
    "gender_df_val_set.columns = ['sex']\n",
    "doc_vec_df_val_set_w_gender = pd.concat([doc_vec_df_val_set,gender_df_val_set], axis = 1)\n",
    "doc_vec_df_val_set_w_gender['sex'] = doc_vec_df_val_set_w_gender['sex'].map(sex_num)\n",
    "X_val = doc_vec_df_val_set_w_gender.drop(['sex'], axis = 1)\n",
    "y_val = doc_vec_df_val_set_w_gender.sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe (gender) for CNN - test set\n",
    "doc_vec_df_test_set = pd.DataFrame(doc_vectors_test)\n",
    "gender_df_test_set = pd.DataFrame(test_set_df['sex'])\n",
    "gender_df_test_set.columns = ['sex']\n",
    "doc_vec_df_test_set_w_gender = pd.concat([doc_vec_df_test_set,gender_df_test_set], axis = 1)\n",
    "doc_vec_df_test_set_w_gender['sex'] = doc_vec_df_test_set_w_gender['sex'].map(sex_num)\n",
    "X_test = doc_vec_df_test_set_w_gender.drop(['sex'], axis = 1)\n",
    "y_test = doc_vec_df_test_set_w_gender.sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, 2)\n",
    "y_val = keras.utils.to_categorical(y_val, 2)\n",
    "y_test = keras.utils.to_categorical(y_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid_model = Sequential()\n",
    "sigmoid_model.add(Dense(100, activation='relu', input_shape=(20,)))\n",
    "sigmoid_model.add(Dense(50, activation='relu'))\n",
    "sigmoid_model.add(Dense(2, activation='sigmoid'))\n",
    "sigmoid_model.compile(loss='binary_crossentropy', optimizer='SGD', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<img src=“MLP architecture.jpg”>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_val = sigmoid_model.fit(X_train, y_train, epochs= 100, batch_size=32, verbose=0, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_train = sigmoid_model.evaluate(X_train, y_train)\n",
    "# results_test = sigmoid_model.evaluate(X_test, y_test)\n",
    "\n",
    "print('Accuracy score for the training set is {:.2f}%'.format(results_train[1]*100))\n",
    "print('Accuracy score for the test set is {:.2f}%'.format(results_train[1]*100)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_val.history\n",
    "# history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "loss_values = history['loss']\n",
    "val_loss_values = history['val_loss']\n",
    "acc_values = history['acc'] \n",
    "val_acc_values = history['val_acc']\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "\n",
    "plt.figure(figsize = (8,2.5))\n",
    "plt.subplot(121)\n",
    "plt.plot(epochs, loss_values, 'g', label='Training loss')\n",
    "plt.plot(epochs, val_loss_values, 'g.', label='Validation loss')\n",
    "\n",
    "plt.title('Training & validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(122)\n",
    "\n",
    "plt.plot(epochs, acc_values, 'r', label='Training acc')\n",
    "plt.plot(epochs, val_acc_values, 'r.', label='Validation acc')\n",
    "plt.title('Training & validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Period Classification (multi-class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe (period) for CNN - train set \n",
    "period_df.columns = ['period']\n",
    "doc_vec_df_with_period = pd.concat([doc_vec_df,period_df], axis = 1)\n",
    "doc_vec_df_with_period['period'] = doc_vec_df_with_period['period'].map(period_num)\n",
    "X_train_period = doc_vec_df_with_period.drop(['period'], axis = 1)\n",
    "y_train_period = doc_vec_df_with_period.period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe (period) for CNN - validation set\n",
    "period_df_val_set = pd.DataFrame(validation_set_df['period'])\n",
    "period_df_val_set.columns = ['period']\n",
    "doc_vec_df_val_set_w_period = pd.concat([doc_vec_df_val_set,period_df_val_set], axis = 1)\n",
    "doc_vec_df_val_set_w_period['period'] = doc_vec_df_val_set_w_period['period'].map(period_num)\n",
    "X_val_period = doc_vec_df_val_set_w_period.drop(['period'], axis = 1)\n",
    "y_val_period = doc_vec_df_val_set_w_period.period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe (period) for CNN - test set\n",
    "period_df_test_set = pd.DataFrame(test_set_df['period'])\n",
    "period_df_test_set.columns = ['period']\n",
    "doc_vec_df_test_set_w_period = pd.concat([doc_vec_df_test_set,period_df_test_set], axis = 1)\n",
    "doc_vec_df_test_set_w_period['period'] = doc_vec_df_test_set_w_period['period'].map(period_num)\n",
    "X_test_period = doc_vec_df_test_set_w_period.drop(['period'], axis = 1)\n",
    "y_test_period = doc_vec_df_test_set_w_period.period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_period = keras.utils.to_categorical(y_train_period, len(period_num))\n",
    "y_val_period = keras.utils.to_categorical(y_val_period, len(period_num))\n",
    "y_test_period = keras.utils.to_categorical(y_test_period, len(period_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_model_period = Sequential()\n",
    "softmax_model_period.add(Dense(100, activation='relu', input_shape=(20,)))\n",
    "softmax_model_period.add(Dense(50, activation='relu'))\n",
    "softmax_model_period.add(Dense(2, activation='softmax'))\n",
    "softmax_model_period.compile(loss='categorical_crossentropy', optimizer='SGD', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_model_period.fit(X_train, y_train, epochs= 100, batch_size=32, verbose=0, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Doc2Vec by Unique ID\n",
    "- instead of using the target labels (gender, author, etc..), use unique id as label \n",
    "- this is going to give us the vector representation of each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TaggedDocument objects for train_corpus_unique_id\n",
    "train_corpus_unique_id = []\n",
    "for i in range(0, len(train_set_df)):\n",
    "    doc = TaggedDocument(train_set_df['text'][i].split(), [i])   \n",
    "    train_corpus_unique_id.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_unique_id = Doc2Vec(vector_size=vec_size,\n",
    "                min_count=min_count,\n",
    "                epochs=epochs,\n",
    "                alpha = alpha,\n",
    "                min_alpha = min_alpha)\n",
    "\n",
    "model_unique_id.build_vocab(train_corpus_unique_id)\n",
    "\n",
    "%time model_unique_id.train(train_corpus_unique_id, total_examples = model.corpus_count, epochs = model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = []\n",
    "second_ranks = []\n",
    "for doc_id in range(len(train_corpus_unique_id)):\n",
    "    inferred_vector = model_unique_id.infer_vector(train_corpus_unique_id[doc_id].words)\n",
    "    sims = model_unique_id.docvecs.most_similar([inferred_vector], topn=len(model_unique_id.docvecs))\n",
    "    rank = [docid for docid, sim in sims].index(doc_id)\n",
    "    ranks.append(rank)\n",
    "    #see how many it got correct and how many it didn't \n",
    "counter = Counter(ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy \n",
    "counter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_vectors_unique_id = [model_unique_id.infer_vector(train_corpus_unique_id[i].words) for i in range(0,len(train_corpus_unique_id))]\n",
    "doc_vectors_unique_id_df = pd.DataFrame(doc_vectors_unique_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_labels = train_set_df[['author', 'sex', 'period']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce dimensionality to visualize the document vectors \n",
    "pca_unique = PCA(n_components = 3)\n",
    "pca_unique.fit(doc_vectors_unique_id)\n",
    "doc_vectors_3d_unique_id = pca_unique.transform(doc_vectors_unique_id) # transform the vectors to 3d space\n",
    "explained_variance_ratio_unique = np.cumsum(pca_unique.explained_variance_ratio_)[2]\n",
    "print('Explained variance ratio is {:.2f}%, {:.2f}% is lost by reducing the dimensionality'.format((explained_variance_ratio_unique*100), (100-(explained_variance_ratio_unique*100)))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_vectors_unique_id_3d_df = pd.DataFrame(doc_vectors_3d_unique_id)\n",
    "doc_vectors_unique_id_3d_df.columns = ['x', 'y', 'z']\n",
    "doc_vec_unique_id_df = pd.concat([doc_vectors_unique_id_3d_df, train_set_labels], axis = 1)\n",
    "doc_vec_unique_id_df['author'] = doc_vec_unique_id_df['author'].map(author_num)\n",
    "doc_vec_unique_id_df['sex'] = doc_vec_unique_id_df['sex'].map(sex_num)\n",
    "doc_vec_unique_id_df['period'] = doc_vec_unique_id_df['period'].map(period_num)\n",
    "\n",
    "doc_vectors_unique_id_df = pd.concat([doc_vectors_unique_id_df, train_set_labels], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_map(category):\n",
    "    cmap = plt.cm.viridis\n",
    "    cmaplist = [cmap(i) for i in range(cmap.N)]\n",
    "    jump = 256//len(category)\n",
    "    cmaplist_ = [cmaplist[jump*i] for i in range(0,len(category))]\n",
    "    return cmaplist_\n",
    "\n",
    "cmap_author = color_map(authors)\n",
    "cmap_sex = color_map(genders)\n",
    "cmap_periods = color_map(periods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.html.widgets import interact\n",
    "def update_plot(w):\n",
    "    if w == 'author':\n",
    "        traces_for_plot_unique = []\n",
    "        for key, value in author_num.items():\n",
    "            df = doc_vec_unique_id_df[doc_vec_unique_id_df['author'] == value]\n",
    "            traces_for_plot_unique.append(df)\n",
    "\n",
    "        traces_unique_author = []\n",
    "        for trace in traces_for_plot_unique:\n",
    "            trace1 = go.Scatter3d(\n",
    "            x = trace['x'],\n",
    "            y = trace['y'],\n",
    "            z = trace['z'],\n",
    "            mode='markers',\n",
    "            name = authors[trace['author'].values[0]],\n",
    "            marker=dict(\n",
    "                size=5,\n",
    "                color= 'rgba' + str(cmap_author[(trace['author'].values[0])]),\n",
    "            )\n",
    "            )\n",
    "            traces_unique_author.append(trace1)\n",
    "        layout = go.Layout(showlegend=True)\n",
    "        fig = go.Figure(data= traces_unique_author, layout = layout)\n",
    "        iplot(fig, filename='test1')\n",
    "    if w == 'gender':\n",
    "        traces_for_plot_unique_sex = []\n",
    "        for key, value in sex_num.items():\n",
    "            df = doc_vec_unique_id_df[doc_vec_unique_id_df['sex'] == value]\n",
    "            traces_for_plot_unique_sex.append(df)\n",
    "\n",
    "        traces_unique_gender = []\n",
    "        for trace in traces_for_plot_unique_sex:\n",
    "            trace1 = go.Scatter3d(\n",
    "            x = trace['x'],\n",
    "            y = trace['y'],\n",
    "            z = trace['z'],\n",
    "            mode='markers',\n",
    "            name = genders[trace['sex'].values[0]],\n",
    "            marker=dict(\n",
    "                size=5,\n",
    "                color= 'rgba' + str(cmap_sex[(trace['sex'].values[0])]),\n",
    "            )\n",
    "            )\n",
    "            traces_unique_gender.append(trace1)\n",
    "\n",
    "        layout = go.Layout(showlegend=True)\n",
    "        # # Make a figure object\n",
    "        fig = go.Figure(data= traces_unique_gender, layout = layout)\n",
    "\n",
    "        # Send to Plotly and show in notebook\n",
    "        iplot(fig, filename='test1')\n",
    "    if w == 'time period':\n",
    "        traces_for_plot_unique_period = []\n",
    "        for key, value in period_num.items():\n",
    "            df = doc_vec_unique_id_df[doc_vec_unique_id_df['period'] == value]\n",
    "            traces_for_plot_unique_period.append(df)\n",
    "\n",
    "        traces_unique_period = []\n",
    "        for trace in traces_for_plot_unique_period:\n",
    "            trace1 = go.Scatter3d(\n",
    "            x = trace['x'],\n",
    "            y = trace['y'],\n",
    "            z = trace['z'],\n",
    "            mode='markers',\n",
    "            name = periods[trace['period'].values[0]],\n",
    "            marker=dict(\n",
    "                size=5,\n",
    "                color= 'rgba' + str(cmap_periods[(trace['period'].values[0])]),\n",
    "            )\n",
    "            )\n",
    "            traces_unique_period.append(trace1)\n",
    "\n",
    "        layout = go.Layout(showlegend=True)\n",
    "        # # Make a figure object\n",
    "        fig = go.Figure(data= traces_unique_period, layout = layout)\n",
    "\n",
    "        # Send to Plotly and show in notebook\n",
    "        iplot(fig, filename='test1')\n",
    "\n",
    "w = widgets.Dropdown(\n",
    "    options= ['author','gender','time period'],\n",
    "    value='author',\n",
    "    description='Category:',\n",
    "    disabled=False)\n",
    "# w.observe(update_plot)\n",
    "interact(update_plot, w=w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_vectors_unique_id_df.to_csv('document_vectors_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP for Unique-ID Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe (gender) for CNN - train set \n",
    "doc_vectors_unique_id_df['sex'] = doc_vectors_unique_id_df['sex'].map(sex_num)\n",
    "X_train_unique_id = doc_vectors_unique_id_df.drop(['author', 'sex', 'period'], axis = 1)\n",
    "y_train_unique_id = doc_vectors_unique_id_df.sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector representation of all documents in list form (for validation set)\n",
    "doc_vectors_val_unique = [model_unique_id.infer_vector(val_corpus[i]) for i in range(0,len(val_corpus))]\n",
    "# vector representation of all documents in list form (for test set)\n",
    "doc_vectors_test_unique = [model_unique_id.infer_vector(test_corpus[i]) for i in range(0,len(test_corpus))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe (gender) for CNN - validation set\n",
    "doc_vec_df_unique_id_val_set = pd.DataFrame(doc_vectors_val_unique)\n",
    "gender_df_val_set_unique = pd.DataFrame(validation_set_df['sex'])\n",
    "gender_df_val_set_unique.columns = ['sex']\n",
    "doc_vec_df_val_set_w_gender_unique = pd.concat([doc_vec_df_unique_id_val_set,gender_df_val_set_unique], axis = 1)\n",
    "doc_vec_df_val_set_w_gender_unique['sex'] = doc_vec_df_val_set_w_gender_unique['sex'].map(sex_num)\n",
    "X_val_unique = doc_vec_df_val_set_w_gender_unique.drop(['sex'], axis = 1)\n",
    "y_val_unique = doc_vec_df_val_set_w_gender_unique.sex\n",
    "\n",
    "# create a dataframe (gender) for CNN - test set\n",
    "doc_vec_df_test_set_unique = pd.DataFrame(doc_vectors_test_unique)\n",
    "gender_df_test_set_unique = pd.DataFrame(test_set_df['sex'])\n",
    "gender_df_test_set_unique.columns = ['sex']\n",
    "doc_vec_df_test_set_w_gender_unique = pd.concat([doc_vec_df_test_set_unique,gender_df_test_set_unique], axis = 1)\n",
    "doc_vec_df_test_set_w_gender_unique['sex'] = doc_vec_df_test_set_w_gender_unique['sex'].map(sex_num)\n",
    "X_test_unique = doc_vec_df_test_set_w_gender_unique.drop(['sex'], axis = 1)\n",
    "y_test_unique = doc_vec_df_test_set_w_gender_unique.sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_unique_id = keras.utils.to_categorical(y_train_unique_id, 2)\n",
    "y_val_unique = keras.utils.to_categorical(y_val_unique, 2)\n",
    "y_test_unique = keras.utils.to_categorical(y_test_unique, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid_model_unique = Sequential()\n",
    "sigmoid_model_unique.add(Dense(100, activation='relu', input_shape=(20,)))\n",
    "sigmoid_model_unique.add(Dense(50, activation='relu'))\n",
    "sigmoid_model_unique.add(Dense(2, activation='sigmoid'))\n",
    "sigmoid_model_unique.compile(loss='binary_crossentropy', optimizer='SGD', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_unique = sigmoid_model_unique.fit(X_train_unique_id, y_train_unique_id, epochs= 100, batch_size=32, verbose=0, validation_data=(X_val_unique, y_val_unique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_unique_id = model_unique.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "loss_values_unique_id = history_unique_id['loss']\n",
    "val_loss_values_unique_id = history_unique_id['val_loss']\n",
    "acc_values_unique_id = history_unique_id['acc'] \n",
    "val_acc_values_unique_id = history_unique_id['val_acc']\n",
    "epochs_unique_id = range(1, len(loss_values_unique_id) + 1)\n",
    "\n",
    "plt.figure(figsize = (8,2.5))\n",
    "plt.subplot(121)\n",
    "plt.plot(epochs_unique_id, loss_values_unique_id, 'g', label='Training loss')\n",
    "plt.plot(epochs_unique_id, val_loss_values_unique_id, 'g.', label='Validation loss')\n",
    "\n",
    "plt.title('Training & validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(122)\n",
    "\n",
    "plt.plot(epochs_unique_id, acc_values_unique_id, 'r', label='Training acc')\n",
    "plt.plot(epochs_unique_id, val_acc_values_unique_id, 'r.', label='Validation acc')\n",
    "plt.title('Training & validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_unique_20 = sigmoid_model_unique.fit(X_train_unique_id, y_train_unique_id, epochs= 20, batch_size=32, verbose=0, validation_data=(X_val_unique, y_val_unique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_early_stop = model_unique_20.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_train_unique = sigmoid_model_unique.evaluate(X_train_unique_id, y_train_unique_id)\n",
    "results_test_unique = sigmoid_model_unique.evaluate(X_test_unique, y_test_unique)\n",
    "\n",
    "print('Accuracy score for the training set is {:.2f}%'.format(results_train_unique[1]*100))\n",
    "print('Accuracy score for the test set is {:.2f}%'.format(results_test_unique[1]*100)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "loss_values_unique_id_20 = history_early_stop['loss']\n",
    "val_loss_values_unique_id_20 = history_early_stop['val_loss']\n",
    "acc_values_unique_id_20 = history_early_stop['acc'] \n",
    "val_acc_values_unique_id_20 = history_early_stop['val_acc']\n",
    "epochs_unique_id_20 = range(1, len(loss_values_unique_id_20) + 1)\n",
    "\n",
    "plt.figure(figsize = (8,2.5))\n",
    "plt.subplot(121)\n",
    "plt.plot(epochs_unique_id_20, loss_values_unique_id_20, 'g', label='Training loss - Early Stop')\n",
    "plt.plot(epochs_unique_id_20, val_loss_values_unique_id_20, 'g.', label='Validation loss - Early Stop')\n",
    "\n",
    "plt.title('Training & validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(122)\n",
    "\n",
    "plt.plot(epochs_unique_id_20, acc_values_unique_id_20, 'r', label='Training acc - Early Stop')\n",
    "plt.plot(epochs_unique_id_20, val_acc_values_unique_id_20, 'r.', label='Validation acc - Early Stop')\n",
    "plt.title('Training & validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L1 Regularization (LASSO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_l1 = Sequential()\n",
    "model_l1.add(Dense(100, activation='relu',kernel_regularizer=regularizers.l1(0.005), input_shape=(20,))) #2 hidden layers\n",
    "model_l1.add(Dense(50, kernel_regularizer=regularizers.l1(0.005), activation='relu'))\n",
    "model_l1.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "model_l1.compile(optimizer='SGD',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "L1_model = model_l1.fit(X_train_unique_id, y_train_unique_id,\n",
    "                    epochs=100,\n",
    "                    batch_size=32,\n",
    "                    verbose=0,\n",
    "                    validation_data=(X_val_unique, y_val_unique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_l1 = L1_model.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_train_unique_l1 = model_l1.evaluate(X_train_unique_id, y_train_unique_id)\n",
    "results_test_unique_l1 = model_l1.evaluate(X_test_unique, y_test_unique)\n",
    "\n",
    "print('Accuracy score for the training set is {:.2f}%'.format(results_train_unique_l1[1]*100))\n",
    "print('Accuracy score for the test set is {:.2f}%'.format(results_test_unique_l1[1]*100)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L2 Regularization (Ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_l2 = Sequential()\n",
    "model_l2.add(Dense(100, activation='relu',kernel_regularizer=regularizers.l2(0.005), input_shape=(20,))) #2 hidden layers\n",
    "model_l2.add(Dense(50, kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model_l2.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "model_l2.compile(optimizer='SGD',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "L2_model = model_l2.fit(X_train_unique_id, y_train_unique_id,\n",
    "                    epochs=100,\n",
    "                    batch_size=32,\n",
    "                    verbose=0,\n",
    "                    validation_data=(X_val_unique, y_val_unique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_l2 = L2_model.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_train_unique_l2 = model_l2.evaluate(X_train_unique_id, y_train_unique_id)\n",
    "results_test_unique_l2 = model_l2.evaluate(X_test_unique, y_test_unique)\n",
    "\n",
    "print('Accuracy score for the training set is {:.2f}%'.format(results_train_unique_l2[1]*100))\n",
    "print('Accuracy score for the test set is {:.2f}%'.format(results_test_unique_l2[1]*100)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dropout = Sequential()\n",
    "model_dropout.add(Dense(100, activation='relu', input_shape=(20,))) #2 hidden layers\n",
    "model_dropout.add(Dropout(0.3))\n",
    "model_dropout.add(Dense(50, activation='relu'))\n",
    "model_dropout.add(Dropout(0.3))\n",
    "model_dropout.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "model_dropout.compile(optimizer='SGD',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "dropout_model = model_dropout.fit(X_train_unique_id, y_train_unique_id,\n",
    "                    epochs=100,\n",
    "                    batch_size=32,\n",
    "                    verbose = 0,\n",
    "                    validation_data=(X_val_unique, y_val_unique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dropout = dropout_model.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_train_unique_dropout = model_dropout.evaluate(X_train_unique_id, y_train_unique_id)\n",
    "results_test_unique_dropout = model_dropout.evaluate(X_test_unique, y_test_unique)\n",
    "\n",
    "print('Accuracy score for the training set is {:.2f}%'.format(results_train_unique_dropout[1]*100))\n",
    "print('Accuracy score for the test set is {:.2f}%'.format(results_test_unique_dropout[1]*100)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "# L1\n",
    "loss_values_l1 = history_l1['loss']\n",
    "val_loss_values_l1 = history_l1['val_loss']\n",
    "acc_values_l1 = history_l1['acc'] \n",
    "val_acc_values_l1 = history_l1['val_acc']\n",
    "epochs_l1 = range(1, len(loss_values_l1) + 1)\n",
    "\n",
    "# L2\n",
    "loss_values_l2 = history_l2['loss']\n",
    "val_loss_values_l2 = history_l2['val_loss']\n",
    "acc_values_l2 = history_l2['acc'] \n",
    "val_acc_values_l2 = history_l2['val_acc']\n",
    "epochs_l2 = range(1, len(loss_values_l2) + 1)\n",
    "\n",
    "# Dropout\n",
    "loss_values_dropout = history_dropout['loss']\n",
    "val_loss_values_dropout = history_dropout['val_loss']\n",
    "acc_values_dropout = history_dropout['acc'] \n",
    "val_acc_values_dropout = history_dropout['val_acc']\n",
    "epochs_dropout = range(1, len(loss_values_dropout) + 1)\n",
    "\n",
    "plt.figure(figsize = (8,3))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(epochs_l1, loss_values_l1, 'g', label='Training loss - L1')\n",
    "plt.plot(epochs_l1, val_loss_values_l1, 'g.', label='Validation loss - L1')\n",
    "plt.plot(epochs_l2, loss_values_l2, 'r', label='Training loss - L2')\n",
    "plt.plot(epochs_l2, val_loss_values_l2, 'r.', label='Validation loss - L2')\n",
    "plt.plot(epochs_dropout, loss_values_dropout, 'b', label='Training loss - Dropout')\n",
    "plt.plot(epochs_dropout, val_loss_values_dropout, 'b.', label='Validation loss - Dropout')\n",
    "\n",
    "plt.title('Training & validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(epochs_l1, acc_values_l1, 'g', label='Training acc - L1')\n",
    "plt.plot(epochs_l1, val_acc_values_l1, 'g.', label='Validation acc - L1')\n",
    "plt.plot(epochs_l2, acc_values_l2, 'r', label='Training acc - L2')\n",
    "plt.plot(epochs_l2, val_acc_values_l2, 'r.', label='Validation acc - L2')\n",
    "plt.plot(epochs_dropout, acc_values_dropout, 'b', label='Training acc - Dropout')\n",
    "plt.plot(epochs_dropout, val_acc_values_dropout, 'b.', label='Validation acc - Dropout')\n",
    "\n",
    "plt.title('Training & validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization\n",
    "#### He Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_he = Sequential()\n",
    "model_he.add(Dense(100, input_shape=(20,), kernel_initializer= \"he_normal\",\n",
    "                kernel_regularizer=regularizers.l2(0.005),\n",
    "                activation='relu'))\n",
    "model_he.add(Dropout(0.3))\n",
    "model_he.add(Dense(50, kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model_he.add(Dropout(0.3))\n",
    "model_he.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "model_he.compile(optimizer= \"sgd\" ,loss='binary_crossentropy',metrics=['accuracy'])\n",
    "he_ini = model_he.fit(X_train_unique_id, y_train_unique_id, batch_size=32, \n",
    "                 epochs=30, validation_data = (X_val_unique, y_val_unique),verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_train_unique_he = model_he.evaluate(X_train_unique_id, y_train_unique_id)\n",
    "results_test_unique_he = model_he.evaluate(X_test_unique, y_test_unique)\n",
    "\n",
    "print('Accuracy score for the training set is {:.2f}%'.format(results_train_unique_he[1]*100))\n",
    "print('Accuracy score for the test set is {:.2f}%'.format(results_test_unique_he[1]*100)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lecun_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lecun = Sequential()\n",
    "model_lecun.add(Dense(100, input_shape=(20,), kernel_initializer= \"lecun_normal\",\n",
    "                kernel_regularizer=regularizers.l2(0.005),\n",
    "                activation='relu'))\n",
    "model_lecun.add(Dropout(0.3))\n",
    "model_lecun.add(Dense(50, kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model_lecun.add(Dropout(0.3))\n",
    "model_lecun.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "model_lecun.compile(optimizer= \"sgd\" ,loss='binary_crossentropy',metrics=['accuracy'])\n",
    "lecun_ini = model_lecun.fit(X_train_unique_id, y_train_unique_id, batch_size=32, \n",
    "                 epochs=30, validation_data = (X_val_unique, y_val_unique),verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_train_unique_lecun = model_lecun.evaluate(X_train_unique_id, y_train_unique_id)\n",
    "results_test_unique_lecun = model_lecun.evaluate(X_test_unique, y_test_unique)\n",
    "\n",
    "print('Accuracy score for the training set is {:.2f}%'.format(results_train_unique_lecun[1]*100))\n",
    "print('Accuracy score for the test set is {:.2f}%'.format(results_test_unique_lecun[1]*100)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization\n",
    "#### RMSProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_he.compile(optimizer= \"rmsprop\" ,loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model_rmsprop = model_he.fit(X_train_unique_id, y_train_unique_id, batch_size=32, \n",
    "                 epochs=30, validation_data = (X_val_unique, y_val_unique),verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_train_rmsprop = model_he.evaluate(X_train_unique_id, y_train_unique_id)\n",
    "results_test_rmsprop = model_he.evaluate(X_test_unique, y_test_unique)\n",
    "\n",
    "print('Accuracy score for the training set is {}%'.format(round(results_train_rmsprop[1]*100),2))\n",
    "print('Accuracy score for the test set is {}%'.format(round(results_test_rmsprop[1]*100),2)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_he.compile(optimizer= \"Adam\" ,loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model_adam = model_he.fit(X_train_unique_id, y_train_unique_id, batch_size=32, \n",
    "                 epochs=30, validation_data = (X_val_unique, y_val_unique),verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_train_adam = model_he.evaluate(X_train_unique_id, y_train_unique_id)\n",
    "results_test_adam = model_he.evaluate(X_test_unique, y_test_unique)\n",
    "\n",
    "print('Accuracy score for the training set is {}%'.format(round(results_train_adam[1]*100),2))\n",
    "print('Accuracy score for the test set is {}%'.format(round(results_test_adam[1]*100),2)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning Rate Decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_learning_rate = optimizers.SGD(lr=0.03, decay=0.0001, momentum=0.9)\n",
    "model_he.compile(optimizer= sgd_learning_rate ,loss='binary_crossentropy',metrics=['accuracy'])\n",
    "learning_rate_decay = model_he.fit(X_train_unique_id, y_train_unique_id, batch_size=32, \n",
    "                 epochs=30, validation_data = (X_val_unique, y_val_unique), verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_train_lrd = model_he.evaluate(X_train_unique_id, y_train_unique_id)\n",
    "results_test_lrd = model_he.evaluate(X_test_unique, y_test_unique)\n",
    "\n",
    "print('Accuracy score for the training set is {}%'.format(round(results_train_lrd[1]*100),2))\n",
    "print('Accuracy score for the test set is {}%'.format(round(results_test_lrd[1]*100),2)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shallow Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also ran a series of shallow learning models for comparison, particularly given that we had a smaller dataset (we didn't have 1000 instances of author or period classes). We ran Naive Bayes, Random Forest, AdaBoost, and K-Neighbors. We tried bag of words vectorization with unigrams and bigrams and Tfidf vectorization with unigrams and bigrams.<br><br> \n",
    "Our highest score for author's sex was actually a Bernoulli Naive Bayes using bag of words with bigram, which accurately predicted author's sex on the test with 90.4% accuracy.<br><br>\n",
    "For a work's literary period, our best model on cross-validation was . Random guess chance - 14% <br><br>\n",
    "And for predicting on individual author, our best model on cross-validation was:  Random guess chance - 7%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "|                       |Multinomial NB |Bernoulli NB  | Random Forest |  AdaBoost | K-Nearest Neighbors |\n",
    "|-----------------------|:-------------------|:------------------|:--------------:|:------------|-------|\n",
    "|Test Accuracy Score (Sex)| 88.46% | 90.40%| 80.91%| 78.29%| N/A|\n",
    "|Test Accuracy Score (Period)| N/A | N/A | 63.47%| 43.92%| 55.30%|\n",
    "|Test Accuracy Score (Author)| N/A | N/A | 56.91%| 33.49%| 48.28%|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
